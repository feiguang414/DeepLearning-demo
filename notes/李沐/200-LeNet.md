# 卷积神经网络（`LeNet`）

###### 关于padding

对于步幅为1的情况，如果我们希望卷积层的输出特征图尺寸与输入特征图尺寸相同，那么填充的大小应该满足以下公式：

```python
padding = (kernel_size - 1) / 2
```

这个公式是为了保持卷积核在特征图上滑动时，每个像素位置都能被完整计算到。通过将填充设置为 `(kernel_size - 1) / 2`，卷积核的中心像素可以对齐到输入特征图的中心像素，从而保持输入和输出特征图的尺寸一致。

以你提供的例子 `nn.Conv2d(1, 6, kernel_size=5, padding=2)` 为例，卷积核的大小为5x5，填充的大小为2，这样可以确保卷积核在输入特征图上的每个像素位置都有合适的计算。



###### `LeNet` 的步骤

这段代码定义了一个`LeNet-5`神经网络模型。让我逐步解释每一层的功能：

1. `Reshape()`：将输入数据的形状从任意形状重塑为`[batch_size, 1, 28, 28]`的形状，其中`batch_size`表示样本的数量，`1`表示图像的通道数，`28x28`表示图像的宽度和高度。

2. `nn.Conv2d(1, 6, kernel_size=5, padding=2)`：一个二维卷积层，将输入特征图从1个通道扩展到6个通道。它使用大小为5x5的卷积核，在输入特征图周围添加2个填充。卷积操作会将每个卷积核与输入特征图的局部区域进行元素乘积累加，并输出到下一层。这个卷积层的输出形状是`[batch_size, 6, 28, 28]`。

3. `nn.Sigmoid()`：一个Sigmoid激活函数，将卷积层的输出通过非线性变换，将每个元素的值限制在0到1之间。这个激活函数将逐元素地对张量进行操作，保持输出形状不变，即`[batch_size, 6, 28, 28]`。

4. `nn.AvgPool2d(2, stride=2)`：一个二维平均池化层，将输入特征图按照2x2的窗口进行池化操作，取窗口内值的平均值作为输出。通过指定步幅为2，池化操作将减小特征图的尺寸。这个池化层的输出形状是`[batch_size, 6, 14, 14]`。

5. `nn.Conv2d(6, 16, kernel_size=5)`：另一个二维卷积层，将输入特征图从6个通道扩展到16个通道。它使用大小为5x5的卷积核，没有填充。这个卷积层的输出形状是`[batch_size, 16, 10, 10]`。

6. `nn.Sigmoid()`：又一个Sigmoid激活函数，将卷积层的输出通过非线性变换，将每个元素的值限制在0到1之间。这个激活函数将逐元素地对张量进行操作，保持输出形状不变，即`[batch_size, 16, 10, 10]`。

7. `nn.AvgPool2d(kernel_size=2, stride=2)`：再次使用二维平均池化层，按照2x2的窗口进行池化操作，取窗口内值的平均值作为输出。通过指定步幅为2，池化操作将减小特征图的尺寸。这个池化层的输出形状是`[batch_size, 16, 5, 5]`。

8. `nn.Flatten()`：扁平化层，将输入的多维特征图展平为一维向量。这个层的作用是将池化层输出的特征图转换为一维向量，形状变为`[batch_size, 16*5*5]`。

9. `nn.Linear(16*5*5, 120)`：一个全连接层，将一维向量映射到大小为120的特征向量。这个全连接层的输出形状是`[batch_size, 120]`。neuron的个数是120个

10. `nn.Sigmoid()`：再次使用Sigmoid激活函数，将全连接层的输出通过非线性变换，将每个元素的值限制在0到1之间。这个激活函数将逐元素地对张量进行操作，保持输出形状不变，即`[batch_size, 120]`。

11. `nn.Linear(120, 84)`：另一个全连接层，将大小为120的特征向量映射到大小为84的特征向量。这个全连接层的输出形状是`[batch_size, 84]`。

12. `nn.Sigmoid()`：再次使用Sigmoid激活函数，将全连接层的输出通过非线性变换，将每个元素的值限制在0到1之间。这个激活函数将逐元素地对张量进行操作，保持输出形状不变，即`[batch_size, 84]`。

13. `nn.Linear(84, 10)`：最后一个全连接层，将大小为84的特征向量映射到大小为10的特征向量。这个全连接层的输出形状是`[batch_size, 10]`。10是我们定义的类别

综上所述，这段代码定义了一个`LeNet-5`神经网络模型，用于对28x28的灰度图像进行分类。

###### tips

把图片不断压缩，通道数变多，就是把图片压缩的信息放到了不同的通道中。

###### 图像数据集

Fashion MNIST和ImageNet是两个常用的图像数据集，它们有一些区别：

1. Fashion MNIST数据集：Fashion MNIST是一个包含10个类别的图像数据集，每个类别有6000个样本图像。每个图像的尺寸为28x28像素，且为灰度图像（单通道）。该数据集通常用于验证和测试深度学习模型的图像分类性能。
2. ImageNet数据集：ImageNet是一个庞大的图像数据库，它包含超过一百万张图像，用于1000个不同类别的图像分类任务。每个图像的分辨率较高，通常为几百像素或更多。ImageNet数据集包含各种物体的图像，涵盖了更广泛的场景和类别。

对于通道数的不同，是因为图像的颜色表示方式不同：

- Fashion MNIST数据集中的图像是灰度图像，每个像素的取值范围为0到255之间的整数，因此只有一个通道。通道中的像素值表示灰度级别，可以用一个数值来表示图像的灰度。
- ImageNet数据集中的图像是彩色图像，每个像素由红色（R）、绿色（G）和蓝色（B）三个通道组成，每个通道的取值范围也是0到255之间的整数。彩色图像的每个像素包含了丰富的颜色信息，通过组合不同通道的像素值，可以得到具有丰富颜色信息的图像。

因此，根据不同数据集的特点和图像的颜色表示方式，通道数会有所不同。在这段代码中，Fashion MNIST数据集是灰度图像，所以输入通道数为1。如果使用的是ImageNet数据集，图像是彩色图像，通道数应为3，对应红、绿、蓝三个通道。

